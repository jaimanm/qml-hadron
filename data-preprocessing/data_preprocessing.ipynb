{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4d7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80916840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pid</th>\n",
       "      <th>Particle_px</th>\n",
       "      <th>Particle_py</th>\n",
       "      <th>Particle_pz</th>\n",
       "      <th>Particle_E</th>\n",
       "      <th>Particle_pT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pi0</td>\n",
       "      <td>111</td>\n",
       "      <td>0.160985</td>\n",
       "      <td>0.235890</td>\n",
       "      <td>36.980500</td>\n",
       "      <td>36.981800</td>\n",
       "      <td>0.285588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pi0</td>\n",
       "      <td>111</td>\n",
       "      <td>0.236153</td>\n",
       "      <td>0.365678</td>\n",
       "      <td>22.802300</td>\n",
       "      <td>22.806800</td>\n",
       "      <td>0.435303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pi-</td>\n",
       "      <td>-211</td>\n",
       "      <td>0.072274</td>\n",
       "      <td>0.046684</td>\n",
       "      <td>0.632455</td>\n",
       "      <td>0.653362</td>\n",
       "      <td>0.086040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pi-</td>\n",
       "      <td>-211</td>\n",
       "      <td>0.036291</td>\n",
       "      <td>0.250416</td>\n",
       "      <td>41.818200</td>\n",
       "      <td>41.819200</td>\n",
       "      <td>0.253032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pi0</td>\n",
       "      <td>111</td>\n",
       "      <td>-0.149215</td>\n",
       "      <td>0.046229</td>\n",
       "      <td>8.431800</td>\n",
       "      <td>8.434330</td>\n",
       "      <td>0.156212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event Name  Pid  Particle_px  Particle_py  Particle_pz  Particle_E  \\\n",
       "0      0  pi0  111     0.160985     0.235890    36.980500   36.981800   \n",
       "1      1  pi0  111     0.236153     0.365678    22.802300   22.806800   \n",
       "2      2  pi- -211     0.072274     0.046684     0.632455    0.653362   \n",
       "3      3  pi- -211     0.036291     0.250416    41.818200   41.819200   \n",
       "4      4  pi0  111    -0.149215     0.046229     8.431800    8.434330   \n",
       "\n",
       "   Particle_pT  \n",
       "0     0.285588  \n",
       "1     0.435303  \n",
       "2     0.086040  \n",
       "3     0.253032  \n",
       "4     0.156212  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('first_emission_50gev.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce416f",
   "metadata": {},
   "source": [
    "# Data Preprocessing Steps\n",
    "1. Ensure 4 * 10^5 events\n",
    "2. Columns used: pT, pz\n",
    "3. Rescale pz to pz' using a reference energy of 50 GeV\n",
    "- $p_{z}^{\\prime}\\equiv E_{ref}\\frac{p}{E}$\n",
    "4. Split into two training sets: one for pT and one for pz'\n",
    "4. Randomly partition into batches/vectors of size 100\n",
    "5. Sort each vector in increasing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3159dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of events: 10000\n",
      "Target number of events: 400,000\n",
      "\n",
      "Note: We have 10000 events, which is less than 400,000\n",
      "We'll work with the available data for now\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check current number of events\n",
    "print(f\"Current number of events: {len(df)}\")\n",
    "print(f\"Target number of events: 400,000\")\n",
    "\n",
    "# If we need more events, we'll need to generate more data\n",
    "# For now, let's work with what we have and we can duplicate/bootstrap if needed\n",
    "if len(df) < 400000:\n",
    "    print(f\"\\nNote: We have {len(df)} events, which is less than 400,000\")\n",
    "    print(\"We'll work with the available data for now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a109752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original pz range: [0.254, 49.526]\n",
      "Rescaled pz' range: [42.608, 50.000]\n",
      "pT range: [0.002, 1.706]\n"
     ]
    }
   ],
   "source": [
    "# Step 2 & 3: Extract pT and pz columns, and rescale pz to pz'\n",
    "# pz' = E_ref * (pz / E) where E_ref = 50 GeV\n",
    "\n",
    "E_ref = 50.0  # Reference energy in GeV\n",
    "\n",
    "# Extract columns\n",
    "pT = df['Particle_pT'].values\n",
    "pz = df['Particle_pz'].values\n",
    "E = df['Particle_E'].values\n",
    "\n",
    "# Calculate pz' (rescaled pz)\n",
    "pz_prime = E_ref * (pz / E)\n",
    "\n",
    "print(f\"Original pz range: [{pz.min():.3f}, {pz.max():.3f}]\")\n",
    "print(f\"Rescaled pz' range: [{pz_prime.min():.3f}, {pz_prime.max():.3f}]\")\n",
    "print(f\"pT range: [{pT.min():.3f}, {pT.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "014384a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set for pT: 10000 events\n",
      "Training set for pz': 10000 events\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Split into two training sets\n",
    "# One for pT and one for pz'\n",
    "\n",
    "training_pT = pT.copy()\n",
    "training_pz_prime = pz_prime.copy()\n",
    "\n",
    "print(f\"Training set for pT: {len(training_pT)} events\")\n",
    "print(f\"Training set for pz': {len(training_pz_prime)} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62229391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pT batches shape: (100, 100)\n",
      "pz' batches shape: (100, 100)\n",
      "\n",
      "Number of batches: 100\n",
      "Batch size: 100\n",
      "\n",
      "Example of first batch (pT):\n",
      "  First 5 values: [0.0181661 0.0658976 0.0662864 0.0906684 0.0908882]\n",
      "  Last 5 values: [0.587231 0.591635 0.66802  0.681434 0.775617]\n",
      "  Min: 0.0182, Max: 0.7756\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Randomly partition into batches/vectors of size 100 and sort each vector\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "def create_sorted_batches(data, batch_size=100):\n",
    "    \"\"\"\n",
    "    Randomly partition data into batches of given size and sort each batch.\n",
    "    \"\"\"\n",
    "    # Shuffle the data randomly\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    shuffled_data = data.copy()\n",
    "    np.random.shuffle(shuffled_data)\n",
    "    \n",
    "    # Calculate number of complete batches\n",
    "    n_batches = len(shuffled_data) // batch_size\n",
    "    \n",
    "    # Trim data to fit complete batches\n",
    "    trimmed_data = shuffled_data[:n_batches * batch_size]\n",
    "    \n",
    "    # Reshape into batches\n",
    "    batches = trimmed_data.reshape(n_batches, batch_size)\n",
    "    \n",
    "    # Sort each batch\n",
    "    sorted_batches = np.sort(batches, axis=1)\n",
    "    \n",
    "    return sorted_batches\n",
    "\n",
    "# Create sorted batches for both pT and pz'\n",
    "pT_batches = create_sorted_batches(training_pT, batch_size)\n",
    "pz_prime_batches = create_sorted_batches(training_pz_prime, batch_size)\n",
    "\n",
    "print(f\"pT batches shape: {pT_batches.shape}\")\n",
    "print(f\"pz' batches shape: {pz_prime_batches.shape}\")\n",
    "print(f\"\\nNumber of batches: {pT_batches.shape[0]}\")\n",
    "print(f\"Batch size: {pT_batches.shape[1]}\")\n",
    "print(f\"\\nExample of first batch (pT):\")\n",
    "print(f\"  First 5 values: {pT_batches[0, :5]}\")\n",
    "print(f\"  Last 5 values: {pT_batches[0, -5:]}\")\n",
    "print(f\"  Min: {pT_batches[0].min():.4f}, Max: {pT_batches[0].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "629672b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying that batches are sorted:\n",
      "Is first pT batch sorted? True\n",
      "Is first pz' batch sorted? True\n",
      "All checked batches are sorted: True\n"
     ]
    }
   ],
   "source": [
    "# Verify sorting within batches\n",
    "print(\"Verifying that batches are sorted:\")\n",
    "print(f\"Is first pT batch sorted? {np.all(pT_batches[0, :-1] <= pT_batches[0, 1:])}\")\n",
    "print(f\"Is first pz' batch sorted? {np.all(pz_prime_batches[0, :-1] <= pz_prime_batches[0, 1:])}\")\n",
    "\n",
    "# Check a few random batches\n",
    "random_indices = np.random.choice(pT_batches.shape[0], size=5, replace=False)\n",
    "all_sorted = True\n",
    "for idx in random_indices:\n",
    "    if not np.all(pT_batches[idx, :-1] <= pT_batches[idx, 1:]):\n",
    "        all_sorted = False\n",
    "        break\n",
    "    if not np.all(pz_prime_batches[idx, :-1] <= pz_prime_batches[idx, 1:]):\n",
    "        all_sorted = False\n",
    "        break\n",
    "\n",
    "print(f\"All checked batches are sorted: {all_sorted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf0ba5",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2abb3857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved:\n",
      "  - pT_batches_sorted.npy: shape (100, 100)\n",
      "  - pz_prime_batches_sorted.npy: shape (100, 100)\n"
     ]
    }
   ],
   "source": [
    "# Save the preprocessed batches as numpy arrays\n",
    "np.save('pT_batches_sorted.npy', pT_batches)\n",
    "np.save('pz_prime_batches_sorted.npy', pz_prime_batches)\n",
    "\n",
    "print(\"Preprocessed data saved:\")\n",
    "print(f\"  - pT_batches_sorted.npy: shape {pT_batches.shape}\")\n",
    "print(f\"  - pz_prime_batches_sorted.npy: shape {pz_prime_batches.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
